{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概述：Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    使深层网络更容易训练的方法 \n",
    "    -->>> 使用更复杂的优化程序：如SGD +momentum动量、RMSProp或Adam\n",
    "    -->>> 改变网络的架构，使其更容易训练\n",
    "    -->>> batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "批量标准化/批量归一化/ batch normalization layer：\n",
    "\n",
    "    通过 减少内部协变位移（Reducing Internal Covariate Shift）来加速深度网络训练\n",
    "\n",
    "    在训练时 使用 minibatch数据 估计每个特征的均值和标准偏差\n",
    "\n",
    "    这些 估计的均值和标准偏差 用来 中心化和标准化 minibatch特征\n",
    "\n",
    "    在训练时 这些 估计的均值和标准偏差的 running average 保持着\n",
    "    在测试时 这些  running average 用于 中心化和标准化 特性\n",
    "\n",
    "    batch normalization layer包括 \n",
    "       learnable shift（可学习的转移）\n",
    "       每个特性维度的刻度参数（scale parameters）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各代码库 说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run the following from the cs231n directory and try again:\n",
      "python setup.py build_ext --inplace\n",
      "You may also need to restart your iPython kernel\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from classifiers.fc_net import *\n",
    "from data_utils import get_CIFAR10_data\n",
    "from gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from solver import Solver\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # 设置 size\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理模块\n",
    "- 导入 已预处理过的 data\n",
    "- data_utils.py  --> get_CIFAR10_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('y_val: ', (1000,))\n",
      "('X_test: ', (1000, 3, 32, 32))\n",
      "('y_test: ', (1000,))\n",
      "('y_train: ', (49000,))\n",
      "('X_train: ', (49000, 3, 32, 32))\n",
      "('X_val: ', (1000, 3, 32, 32))\n"
     ]
    }
   ],
   "source": [
    "data = get_CIFAR10_data()\n",
    "for k, v in list(data.items()):\n",
    "  print(('%s: ' % k, v.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 普通层模块：Batch normalization: Forward\n",
    "- `layers.py` --> `batchnorm_forward`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 普通层模块：Batch Normalization: backward\n",
    "- `layers.py` --> `batchnorm_backward`.\n",
    "\n",
    "为了得到向后的传递，你应该写出批量标准化的计算图，以及通过每个中间节点的支持。\n",
    "\n",
    "一些中间产物可能有多个传出分支;\n",
    "\n",
    "确保在向后通过的这些分支上有多个梯度\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 普通层模块：Batch Normalization: alternative backward \n",
    "\n",
    "    sigmoid backward pass 的实现策略\n",
    "        1、写出 由简单的操作 和 通过所有中间值来backprop 的 计算图\n",
    "        2、在纸上做衍生品：在纸上简化梯度来推导出一个非常简单的公式\n",
    "\n",
    "- `layers.py` --> `batchnorm_backward_alt` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类器模块：FC Nets with Batch Normalization\n",
    "- `classifiers/fc_net.py`--> add batch normalization.\n",
    "\n",
    "\n",
    "    `use_batchnorm` is `True` :\n",
    "       每个 ReLU nonlinearity 前 加入 a batch normalization layer\n",
    "       最后一层的outputs 不需要 normalized.\n",
    "\n",
    "HINT: You might find it useful to define an additional helper layer similar to those in the file `cs231n/layer_utils.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练：Batchnorm for deep networks\n",
    "训练 six-layer network on a subset of 1000 training examples both with and without batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 小实验：Batch normalization and initialization\n",
    "运行一个小实验来研究批量标准化和权重初始化的交互\n",
    "\n",
    "The first cell ：通过不同scales的权重初始化来训练8层网络 both with and without batch normalization  \n",
    "\n",
    "The second layer ：画图 training accuracy, validation set accuracy, and training loss as a function of the weight initialization scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
